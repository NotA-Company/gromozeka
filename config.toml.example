[bot]
# Your Telegram bot token from @BotFather
token = "YOUR_BOT_TOKEN_HERE"
bot_owners = ["YOUR_BOT_OWNER_USERNAME_HERE"]

[bot.defaults]
admin-can-change-settings = true
bot-nicknames = "Громозека, Gro"
llm-message-format = "text"
use-tools = true
save-images = true
parse-images = true

summary-model           = "openrouter-gemma-3-27b-it-free"
private-model           = "openrouter-gemma-3-12b-it-free"
chat-model              = "openrouter-gemma-3-12b-it-free"
fallback-model          = "openrouter-deepseek-chat-v3.1-free"
summary-fallback-model  = "openrouter-deepseek-chat-v3.1-free"
image-model             = "openrouter-gemma-3-27b-it-free"

summary-prompt = "Суммаризируй пользовательские сообщения, предоставленные в JSON формате. Указывай время начала и конца обсуждения и пользователей, кто обсуждал."
parse-image-prompt = "Подробно опиши, что изображено на картинке"
private-prompt = "Ты - Принни: вайбовый, но умный пингвин из Disgaea, мужчина. При ответе ты можешь использовать Markdown форматирование."
chat-prompt    = "Ты - Принни: вайбовый, но умный пингвин из Disgaea мужского пола. При ответе ты можешь использовать Markdown форматирование."

[database]
# Database configuration
path = "bot_data.db"
# Connection pool settings
max_connections = 5
timeout = 30

[logging]
# Logging configuration
level = "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
# Optional: log to file (uncomment to enable)
# file = "logs/gromozeka.log"

[models]
[models.providers]

[models.providers.yc-openai]
type = "yc-openai"
# https://yandex.cloud/ru/docs/foundation-models/operations/get-api-key
folder_id = "FOLDER_ID"
api_key = "API_KEY"

[models.providers.openrouter]
type = "openrouter"
api_key = "API_KEY"

# Possible YC Models: https://yandex.cloud/ru/docs/foundation-models/concepts/generation/models
[[models.models]]
name = "yandexgpt"
provider = "yc-openai"
model_id = "yandexgpt"
model_version = "latest"
temperature = 0.5
context = 32768
support_tools = true

[[models.models]]
name = "yandexgpt-lite"
provider = "yc-openai"
model_id = "yandexgpt-lite"
model_version="latest"
temperature = 0.5
context = 32768
support_tools = false

[[models.models]]
name = "yc-gpt-oss-120b"
provider = "yc-openai"
model_id = "gpt-oss-120b"
model_version="latest"
temperature = 0.5
context = 128000
support_tools = true

[[models.models]]
name = "yc-llama"
provider = "yc-openai"
model_id = "llama"
model_version="latest"
temperature = 0.5
context = 8192
support_tools = true

[[models.models]]
name = "yc-qwen3-235b-a22b-fp8"
provider = "yc-openai"
model_id = "qwen3-235b-a22b-fp8"
model_version="latest"
temperature = 0.5
context = 256000
support_tools = true

[[models.models]]
name = "yc-gemma-3-27b-it"
provider = "yc-openai"
model_id = "gemma-3-27b-it"
model_version="latest"
temperature = 0.5
context = 128000
support_tools = true

# https://openrouter.ai/models
[[models.models]]
name = "openrouter-claude-sonnet-4"
provider = "openrouter"
model_id = "anthropic/claude-sonnet-4"
model_version = "latest"
temparature = 0.3
context = 256000
support_tools = true

[[models.models]]
name = "openrouter-deepseek-chat-v3.1"
provider = "openrouter"
model_id = "deepseek/deepseek-chat-v3.1"
model_version = "latest"
temparature = 0.3
context = 163840
support_tools = true

[[models.models]]
name = "openrouter-deepseek-chat-v3.1-free"
provider = "openrouter"
model_id = "deepseek/deepseek-chat-v3.1:free"
model_version = "latest"
temparature = 0.3
context = 64000
support_tools = true

[[models.models]]
name = "openrouter-gemma-3-27b-it-free"
provider = "openrouter"
model_id = "google/gemma-3-27b-it:free"
model_version = "latest"
temparature = 0.3
context = 96000
support_tools = true

[[models.models]]
name = "openrouter-gemma-3-12b-it-free"
provider = "openrouter"
model_id = "google/gemma-3-12b-it:free"
model_version = "latest"
temparature = 0.3
context = 32768
support_tools = true

[[models.models]]
name = "openrouter-qwen-turbo"
provider = "openrouter"
model_id = "qwen/qwen-turbo"
model_version = "latest"
temparature = 0.3
context = 1000000
support_tools = true
