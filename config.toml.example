[bot]
# Your Telegram bot token from @BotFather
token = "YOUR_BOT_TOKEN_HERE"
bot_owners = ["YOUR_BOT_OWNER_USERNAME_HERE"]
allow_admin_change_channel_settings = true


[bot.models]
summary          = "openrouter-gemma-3-27b-it-free"
private          = "openrouter-gemma-3-12b-it-free"
chat             = "openrouter-gemma-3-12b-it-free"
fallback         = "openrouter-deepseek-chat-v3.1-free"
summary-fallback = "openrouter-deepseek-chat-v3.1-free"

[bot.prompts]
summary = "Суммаризируй пользовательские сообщения, предоставленные в JSON формате. Указывай время начала и конца обсуждения и пользователей, кто обсуждал."
private = "Ты - Принни: вайбовый, но умный пингвин из Disgaea, мужчина. При ответе ты можешь использовать Markdown форматирование."
chat    = "Ты - Принни: вайбовый, но умный пингвин из Disgaea мужского пола. При ответе ты можешь использовать Markdown форматирование."

[database]
# Database configuration
path = "bot_data.db"
# Connection pool settings
max_connections = 5
timeout = 30

[logging]
# Logging configuration
level = "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
# Optional: log to file (uncomment to enable)
# file = "logs/gromozeka.log"

[models]
[models.providers]

[models.providers.yc-sdk]
folder_id = "FOLDER_ID"
# Optional: specify yc profile (uncomment if needed)
#yc_profile = "profile-id"

[models.providers.yc-openai]
# https://yandex.cloud/ru/docs/foundation-models/operations/get-api-key
folder_id = "FOLDER_ID"
api_key = "API_KEY"

[models.providers.openrouter]
api_key = "API_KEY"

# Possible YC Models: https://yandex.cloud/ru/docs/foundation-models/concepts/generation/models
[[models.models]]
name = "yandexgpt"
provider = "yc-sdk"
model_id = "yandexgpt"
model_version = "rc"
temperature = 0.5
context = 32768

[[models.models]]
name = "yandexgpt-lite"
provider = "yc-sdk"
model_id = "yandexgpt-lite"
model_version="rc"
temperature = 0.5
context = 32768

[[models.models]]
name = "yc-gpt-oss-120b"
provider = "yc-openai"
model_id = "gpt-oss-120b"
model_version="latest"
temperature = 0.5
context = 128000

[[models.models]]
name = "yc-llama"
provider = "yc-openai"
model_id = "llama"
model_version="rc"
temperature = 0.5
context = 8192

[[models.models]]
name = "yc-qwen3-235b-a22b-fp8"
provider = "yc-openai"
model_id = "qwen3-235b-a22b-fp8"
model_version="latest"
temperature = 0.5
context = 256000

[[models.models]]
name = "yc-gemma-3-27b-it"
provider = "yc-openai"
model_id = "gemma-3-27b-it"
model_version="latest"
temperature = 0.5
context = 128000

# https://openrouter.ai/models
[[models.models]]
name = "openrouter-claude-sonnet-4"
provider = "openrouter"
model_id = "anthropic/claude-sonnet-4"
model_version = "latest"
temparature = 0.3
context = 256000

[[models.models]]
name = "openrouter-deepseek-chat-v3.1"
provider = "openrouter"
model_id = "deepseek/deepseek-chat-v3.1"
model_version = "latest"
temparature = 0.3
context = 163840

[[models.models]]
name = "openrouter-deepseek-chat-v3.1-free"
provider = "openrouter"
model_id = "deepseek/deepseek-chat-v3.1:free"
model_version = "latest"
temparature = 0.3
context = 64000

[[models.models]]
name = "openrouter-gemma-3-27b-it-free"
provider = "openrouter"
model_id = "google/gemma-3-27b-it:free"
model_version = "latest"
temparature = 0.3
context = 96000

[[models.models]]
name = "openrouter-gemma-3-12b-it-free"
provider = "openrouter"
model_id = "google/gemma-3-12b-it:free"
model_version = "latest"
temparature = 0.3
context = 32768

[[models.models]]
name = "openrouter-qwen-turbo"
provider = "openrouter"
model_id = "qwen/qwen-turbo"
model_version = "latest"
temparature = 0.3
context = 1000000
