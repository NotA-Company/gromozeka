#!/usr/bin/env python3
"""
Comprehensive test suite for Bayes spam filter, dood!

This test suite verifies the functionality of the Bayes filter with:
- Basic functionality tests
- Edge cases for tokenization
- Performance tests with large datasets
- Accuracy tests with realistic spam/ham data
- Per-chat isolation validation
"""

import logging
import os
import sys
import tempfile
import time
from typing import Any, Dict, Iterable, List, Optional

import pytest

# Add project root to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))

from internal.database.bayes_storage import DatabaseBayesStorage  # noqa:E402
from internal.database.wrapper import DatabaseWrapper  # noqa:E402
from lib.bayes_filter import BayesConfig, NaiveBayesFilter  # noqa:E402
from lib.bayes_filter.models import BayesModelStats, ClassStats, TokenStats  # noqa:E402
from lib.bayes_filter.storage_interface import BayesStorageInterface  # noqa:E402
from lib.bayes_filter.tokenizer import MessageTokenizer, TokenizerConfig  # noqa:E402

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============================================================================
# Mock Storage Implementation for Unit Tests
# ============================================================================


class MockBayesStorage(BayesStorageInterface):
    """Mock storage implementation for testing without database, dood!"""

    def __init__(self):
        """Initialize mock storage with in-memory data structures"""
        self.tokens: Dict[int, Dict[str, TokenStats]] = {}  # chat_id -> token -> stats
        self.classStats: Dict[int, Dict[bool, ClassStats]] = {}  # chat_id -> is_spam -> stats
        self.globalTokens: Dict[str, TokenStats] = {}
        self.globalClassStats: Dict[bool, ClassStats] = {
            True: ClassStats(message_count=0, token_count=0),
            False: ClassStats(message_count=0, token_count=0),
        }

    def _getChatTokens(self, chatId: Optional[int]) -> Dict[str, TokenStats]:
        """Get token storage for a specific chat or global"""
        if chatId is None:
            return self.globalTokens
        if chatId not in self.tokens:
            self.tokens[chatId] = {}
        return self.tokens[chatId]

    def _getChatClassStats(self, chatId: Optional[int]) -> Dict[bool, ClassStats]:
        """Get class stats for a specific chat or global"""
        if chatId is None:
            return self.globalClassStats
        if chatId not in self.classStats:
            self.classStats[chatId] = {
                True: ClassStats(message_count=0, token_count=0),
                False: ClassStats(message_count=0, token_count=0),
            }
        return self.classStats[chatId]

    async def getTokenStats(self, tokens: Iterable[str], chatId: Optional[int] = None) -> Dict[str, TokenStats]:
        """Get statistics for specific tokens"""
        chatTokens = self._getChatTokens(chatId)
        return {
            token: chatTokens.get(token, TokenStats(token=token, spamCount=0, hamCount=0, totalCount=0))
            for token in tokens
        }

    async def getClassStats(self, is_spam: bool, chat_id: Optional[int] = None) -> ClassStats:
        """Get statistics for spam or ham class"""
        stats = self._getChatClassStats(chat_id)
        return stats.get(is_spam, ClassStats(message_count=0, token_count=0))

    async def updateTokenStats(
        self, token: str, is_spam: bool, increment: int = 1, chat_id: Optional[int] = None
    ) -> bool:
        """Update token statistics"""
        chatTokens = self._getChatTokens(chat_id)
        if token not in chatTokens:
            chatTokens[token] = TokenStats(token=token, spamCount=0, hamCount=0, totalCount=0)

        if is_spam:
            chatTokens[token].spamCount += increment
        else:
            chatTokens[token].hamCount += increment
        chatTokens[token].totalCount = chatTokens[token].spamCount + chatTokens[token].hamCount
        return True

    async def updateClassStats(
        self, isSpam: bool, messageIncrement: int = 1, tokenIncrement: int = 0, chatId: Optional[int] = None
    ) -> bool:
        """Update class statistics"""
        stats = self._getChatClassStats(chatId)
        stats[isSpam].message_count += messageIncrement
        stats[isSpam].token_count += tokenIncrement
        return True

    async def getAllTokens(self, chat_id: Optional[int] = None) -> List[str]:
        """Get all known tokens"""
        chatTokens = self._getChatTokens(chat_id)
        return list(chatTokens.keys())

    async def getVocabularySize(self, chatId: Optional[int] = None) -> int:
        """Get vocabulary size"""
        chatTokens = self._getChatTokens(chatId)
        return len(chatTokens)

    async def getModelStats(self, chat_id: Optional[int] = None) -> BayesModelStats:
        """Get overall model statistics"""
        stats = self._getChatClassStats(chat_id)
        vocabSize = await self.getVocabularySize(chat_id)
        totalTokens = stats[True].token_count + stats[False].token_count

        return BayesModelStats(
            total_spam_messages=stats[True].message_count,
            total_ham_messages=stats[False].message_count,
            total_tokens=totalTokens,
            vocabulary_size=vocabSize,
            chat_id=chat_id,
        )

    async def clearStats(self, chat_id: Optional[int] = None) -> bool:
        """Clear all statistics"""
        if chat_id is None:
            self.globalTokens.clear()
            self.globalClassStats = {
                True: ClassStats(message_count=0, token_count=0),
                False: ClassStats(message_count=0, token_count=0),
            }
        else:
            if chat_id in self.tokens:
                self.tokens[chat_id].clear()
            if chat_id in self.classStats:
                self.classStats[chat_id] = {
                    True: ClassStats(message_count=0, token_count=0),
                    False: ClassStats(message_count=0, token_count=0),
                }
        return True

    async def batchUpdateTokens(self, token_updates: List[Dict[str, Any]], chat_id: Optional[int] = None) -> bool:
        """Batch update tokens"""
        for update in token_updates:
            await self.updateTokenStats(update["token"], update["is_spam"], update["increment"], chat_id)
        return True

    async def getTopSpamTokens(self, limit: int = 10, chat_id: Optional[int] = None) -> List[TokenStats]:
        """Get top spam tokens"""
        chatTokens = self._getChatTokens(chat_id)
        sortedTokens = sorted(
            chatTokens.values(), key=lambda t: t.spamCount / max(1, t.spamCount + t.hamCount), reverse=True
        )
        return sortedTokens[:limit]

    async def getTopHamTokens(self, limit: int = 10, chat_id: Optional[int] = None) -> List[TokenStats]:
        """Get top ham tokens"""
        chatTokens = self._getChatTokens(chat_id)
        sortedTokens = sorted(
            chatTokens.values(), key=lambda t: t.hamCount / max(1, t.spamCount + t.hamCount), reverse=True
        )
        return sortedTokens[:limit]

    async def cleanupRareTokens(self, min_count: int = 2, chat_id: Optional[int] = None) -> int:
        """Remove rare tokens"""
        chatTokens = self._getChatTokens(chat_id)
        toRemove = [token for token, stats in chatTokens.items() if stats.totalCount < min_count]
        for token in toRemove:
            del chatTokens[token]
        return len(toRemove)


# ============================================================================
# Pytest Fixtures
# ============================================================================


@pytest.fixture
async def mockStorage():
    """Create a mock storage instance for testing"""
    return MockBayesStorage()


@pytest.fixture
async def bayesFilter(mockStorage):
    """Create a Bayes filter with mock storage"""
    config = BayesConfig(perChatStats=True, alpha=1.0, minTokenCount=1, debugLogging=False)
    return NaiveBayesFilter(mockStorage, config)


@pytest.fixture
async def trainedFilter(bayesFilter):
    """Create a pre-trained Bayes filter for testing"""
    # Train with spam messages
    spamMessages = [
        "Buy cheap products now!",
        "Click here for amazing deals!",
        "Free money! Click now!",
        "Urgent! Limited time offer!",
        "Make money fast online!",
    ]
    for msg in spamMessages:
        await bayesFilter.learnSpam(msg, chatId=12345)

    # Train with ham messages
    hamMessages = [
        "Hey, how are you doing today?",
        "Let's meet for coffee tomorrow",
        "The weather is nice today",
        "I finished my homework",
        "What time is the meeting?",
    ]
    for msg in hamMessages:
        await bayesFilter.learnHam(msg, chatId=12345)

    return bayesFilter


# ============================================================================
# Original Tests (Preserved)
# ============================================================================


@pytest.mark.asyncio
async def test_bayes_filter():
    """Test basic Bayes filter functionality, dood!"""

    # Create temporary database
    with tempfile.NamedTemporaryFile(suffix=".db", delete=False) as tmp_db:
        db_path = tmp_db.name

    db: Optional[DatabaseWrapper] = None
    try:
        # Initialize database and storage
        db = DatabaseWrapper({"sources": {"default": {"path": db_path}}, "default": "default"})
        storage = DatabaseBayesStorage(db)

        # Initialize Bayes filter
        config = BayesConfig(perChatStats=True, alpha=1.0, minTokenCount=1, debugLogging=True)  # Lower for testing
        bayes_filter = NaiveBayesFilter(storage, config)

        logger.info("=== Testing Bayes Filter, dood! ===")

        # Test 1: Classification without training (should return neutral)
        logger.info("Test 1: Classification without training")
        result = await bayes_filter.classify("Buy cheap products now!", chatId=12345)
        logger.info(f"Score: {result.score:.2f}%, Is spam: {result.isSpam}, Confidence: {result.confidence:.3f}")
        assert result.score == 50.0, f"Expected neutral score 50.0, got {result.score}"

        # Test 2: Learn some spam messages
        logger.info("Test 2: Learning spam messages")
        spam_messages = [
            "Buy cheap products now!",
            "Click here for amazing deals!",
            "Free money! Click now!",
            "Urgent! Limited time offer!",
            "Make money fast online!",
        ]

        for msg in spam_messages:
            success = await bayes_filter.learnSpam(msg, chatId=12345)
            assert success, f"Failed to learn spam message: {msg}"

        logger.info(f"Learned {len(spam_messages)} spam messages")

        # Test 3: Learn some ham messages
        logger.info("Test 3: Learning ham messages")
        ham_messages = [
            "Hey, how are you doing today?",
            "Let's meet for coffee tomorrow",
            "The weather is nice today",
            "I finished my homework",
            "What time is the meeting?",
        ]

        for msg in ham_messages:
            success = await bayes_filter.learnHam(msg, chatId=12345)
            assert success, f"Failed to learn ham message: {msg}"

        logger.info(f"Learned {len(ham_messages)} ham messages")

        # Test 4: Get model statistics
        logger.info("Test 4: Model statistics")
        stats = await bayes_filter.getModelInfo(chat_id=12345)
        logger.info(
            f"Stats: {stats.total_spam_messages} spam, {stats.total_ham_messages} ham, vocab: {stats.vocabulary_size}"
        )
        assert stats.total_spam_messages == len(spam_messages)
        assert stats.total_ham_messages == len(ham_messages)
        assert stats.vocabulary_size > 0

        # Test 5: Classify spam-like message
        logger.info("Test 5: Classify spam-like message")
        result = await bayes_filter.classify("Buy cheap deals now!", chatId=12345, threshold=50.0)
        logger.info(
            f"Spam-like message - Score: {result.score:.2f}%, Is spam: {result.isSpam}, "
            f"Confidence: {result.confidence:.3f}"
        )
        logger.info(f"Top tokens: {sorted(result.tokenScores.items(), key=lambda x: x[1], reverse=True)[:3]}")

        # Test 6: Classify ham-like message
        logger.info("Test 6: Classify ham-like message")
        result = await bayes_filter.classify("How are you today?", chatId=12345, threshold=50.0)
        logger.info(
            f"Ham-like message - Score: {result.score:.2f}%, Is spam: {result.isSpam}, "
            f"Confidence: {result.confidence:.3f}"
        )
        logger.info(f"Top tokens: {sorted(result.tokenScores.items(), key=lambda x: x[1], reverse=True)[:3]}")

        # Test 7: Test per-chat isolation
        logger.info("Test 7: Per-chat isolation")
        result_other_chat = await bayes_filter.classify("Buy cheap products now!", chatId=67890)
        logger.info(
            f"Other chat - Score: {result_other_chat.score:.2f}%, Confidence: {result_other_chat.confidence:.3f}"
        )
        assert result_other_chat.score == 50.0, "Per-chat isolation failed"

        # Test 8: Batch learning
        logger.info("Test 8: Batch learning")
        batch_messages = [
            ("More spam content here", True, 12345),
            ("Another normal message", False, 12345),
            ("Yet another spam", True, 12345),
        ]

        batch_stats = await bayes_filter.batch_learn(batch_messages)
        logger.info(f"Batch learning stats: {batch_stats}")
        assert batch_stats["success"] == 3
        assert batch_stats["spam_learned"] == 2
        assert batch_stats["ham_learned"] == 1

        # Test 9: Storage interface methods
        logger.info("Test 9: Storage interface methods")

        # Get top spam tokens
        top_spam = await storage.getTopSpamTokens(limit=5, chatId=12345)
        logger.info(f"Top spam tokens: {[(t.token, t.spamCount, t.hamCount) for t in top_spam[:3]]}")

        # Get top ham tokens
        top_ham = await storage.getTopHamTokens(limit=5, chatId=12345)
        logger.info(f"Top ham tokens: {[(t.token, t.spamCount, t.hamCount) for t in top_ham[:3]]}")

        # Test 10: Cleanup rare tokens
        logger.info("Test 10: Cleanup rare tokens")
        removed = await bayes_filter.cleanup_rare_tokens(min_count=2, chat_id=12345)
        logger.info(f"Removed {removed} rare tokens")

        logger.info("=== All tests passed! Bayes filter is working correctly, dood! ===")

    finally:
        # Cleanup
        if db is not None:
            db.close()
        try:
            os.unlink(db_path)
        except Exception:
            pass


@pytest.mark.asyncio
async def test_tokenizer():
    """Test tokenizer functionality, dood!"""
    logger.info("=== Testing Tokenizer, dood! ===")

    # Test basic tokenization
    tokenizer = MessageTokenizer()

    testText = "Buy cheap products now! Visit https://example.com @user123"
    tokens = tokenizer.tokenize(testText)
    logger.info(f"Original: {testText}")
    logger.info(f"Tokens: {tokens}")

    # Test with different config
    config = TokenizerConfig(remove_urls=False, remove_mentions=False, use_bigrams=False)
    tokenizer2 = MessageTokenizer(config)
    tokens2 = tokenizer2.tokenize(testText)
    logger.info(f"With URLs/mentions: {tokens2}")

    # Test spam indicators
    indicators = tokenizer.estimate_spam_indicators(testText)
    logger.info(f"Spam indicators: {indicators}")

    logger.info("=== Tokenizer tests passed, dood! ===")


# ============================================================================
# Edge Cases for Tokenization
# ============================================================================


class TestBayesFilterEdgeCases:
    """Test edge cases for tokenization and message handling, dood!"""

    @pytest.mark.asyncio
    async def test_empty_message(self, bayesFilter):
        """Test classification of empty message"""
        result = await bayesFilter.classify("", chatId=12345)
        assert result.score == 50.0
        assert result.confidence == 0.0
        assert not result.isSpam

    @pytest.mark.asyncio
    async def test_whitespace_only_message(self, bayesFilter):
        """Test classification of whitespace-only message"""
        result = await bayesFilter.classify("   \t\n  ", chatId=12345)
        assert result.score == 50.0
        assert result.confidence == 0.0

    @pytest.mark.asyncio
    async def test_special_characters_only(self, bayesFilter):
        """Test message with only special characters"""
        result = await bayesFilter.classify("!@#$%^&*()", chatId=12345)
        assert result.score == 50.0
        assert result.confidence == 0.0

    @pytest.mark.asyncio
    async def test_emojis_only(self, bayesFilter):
        """Test message with only emojis"""
        result = await bayesFilter.classify("üòÄüòÉüòÑüòÅü§£", chatId=12345)
        # Should return neutral since emojis are removed by default
        assert result.score == 50.0

    @pytest.mark.asyncio
    async def test_very_long_message(self, trainedFilter):
        """Test classification of very long message (10,000+ characters)"""
        longMessage = "spam " * 2500  # 12,500 characters
        result = await trainedFilter.classify(longMessage, chatId=12345)
        # Should still classify (tokens limited by config)
        assert 0 <= result.score <= 100

    @pytest.mark.asyncio
    async def test_mixed_languages(self, bayesFilter):
        """Test message with mixed Russian and English"""
        await bayesFilter.learnSpam("–ö—É–ø–∏—Ç—å cheap products —Å–µ–π—á–∞—Å!", chatId=12345)
        await bayesFilter.learnHam("–ü—Ä–∏–≤–µ—Ç how are you?", chatId=12345)

        result = await bayesFilter.classify("–ö—É–ø–∏—Ç—å cheap —Ç–æ–≤–∞—Ä—ã", chatId=12345)
        assert 0 <= result.score <= 100

    @pytest.mark.asyncio
    async def test_urls_and_emails(self, bayesFilter):
        """Test message with URLs and email addresses"""
        await bayesFilter.learnSpam("Visit http://spam.com and email spam@example.com", chatId=12345)
        await bayesFilter.learnHam("Check out my website", chatId=12345)
        result = await bayesFilter.classify("Check https://test.com", chatId=12345)
        # URLs should be removed by tokenizer, so classification based on other words
        assert 0 <= result.score <= 100

    @pytest.mark.asyncio
    async def test_repeated_characters(self, bayesFilter):
        """Test message with repeated characters"""
        await bayesFilter.learnSpam("aaaaaaaaaa bbbbbbbbbb", chatId=12345)
        await bayesFilter.learnHam("normal text here", chatId=12345)
        result = await bayesFilter.classify("aaaaaaaaaa", chatId=12345)
        assert result.score > 50.0  # Should recognize pattern

    @pytest.mark.asyncio
    async def test_numbers_only(self, bayesFilter):
        """Test message with numbers only"""
        result = await bayesFilter.classify("123456789", chatId=12345)
        # Numbers might be removed depending on config
        assert result.score == 50.0

    @pytest.mark.asyncio
    async def test_unicode_edge_cases(self, bayesFilter):
        """Test various Unicode edge cases"""
        unicodeMessages = [
            "Hello ‰∏ñÁïå",  # Chinese characters
            "ŸÖÿ±ÿ≠ÿ®ÿß hello",  # Arabic
            "–ü—Ä–∏–≤–µ—Ç –º–∏—Ä",  # Cyrillic
            "üéâüéäüéà",  # Emojis
            "caf√© r√©sum√©",  # Accented characters
        ]

        for msg in unicodeMessages:
            result = await bayesFilter.classify(msg, chatId=12345)
            assert 0 <= result.score <= 100

    @pytest.mark.asyncio
    async def test_learn_empty_message(self, bayesFilter):
        """Test learning from empty message"""
        success = await bayesFilter.learnSpam("", chatId=12345)
        assert not success  # Should fail gracefully

    @pytest.mark.asyncio
    async def test_single_character_tokens(self, bayesFilter):
        """Test handling of single character tokens"""
        # Single chars should be filtered by min_token_length
        await bayesFilter.learnSpam("a b c d e", chatId=12345)
        stats = await bayesFilter.getModelInfo(chat_id=12345)
        # Should have minimal or no tokens due to length filter
        assert stats.vocabulary_size == 0


# ============================================================================
# Performance Tests
# ============================================================================


class TestBayesFilterPerformance:
    """Performance tests with large datasets, dood!"""

    @pytest.mark.slow
    @pytest.mark.asyncio
    async def test_large_dataset_training(self, bayesFilter):
        """Test training with 10,000+ messages"""
        startTime = time.time()

        # Generate large dataset
        messages = []
        for i in range(5000):
            messages.append((f"spam message number {i} buy now click here", True, 12345))
            messages.append((f"normal message number {i} hello friend", False, 12345))

        # Batch learn
        stats = await bayesFilter.batch_learn(messages)

        elapsedTime = time.time() - startTime

        assert stats["success"] == 10000
        assert stats["spam_learned"] == 5000
        assert stats["ham_learned"] == 5000
        logger.info(f"Trained 10,000 messages in {elapsedTime:.2f} seconds")

        # Verify model stats
        modelStats = await bayesFilter.getModelInfo(chat_id=12345)
        assert modelStats.total_spam_messages == 5000
        assert modelStats.total_ham_messages == 5000

    @pytest.mark.slow
    @pytest.mark.asyncio
    async def test_classification_speed(self, trainedFilter):
        """Test classification speed with trained model"""
        testMessages = [
            "Buy cheap products now!",
            "Hello how are you?",
            "Click here for deals!",
            "Let's meet tomorrow",
        ] * 250  # 1000 messages

        startTime = time.time()

        for msg in testMessages:
            await trainedFilter.classify(msg, chatId=12345)

        elapsedTime = time.time() - startTime
        avgTime = elapsedTime / len(testMessages)

        logger.info(f"Classified {len(testMessages)} messages in {elapsedTime:.2f}s (avg: {avgTime * 1000:.2f}ms)")
        assert avgTime < 0.1  # Should be fast (< 100ms per message)

    @pytest.mark.slow
    @pytest.mark.asyncio
    async def test_large_vocabulary_performance(self, bayesFilter):
        """Test performance with large vocabulary"""
        # Train with many unique words
        for i in range(1000):
            await bayesFilter.learnSpam(f"unique_spam_word_{i} buy now", chatId=12345)
            await bayesFilter.learnHam(f"unique_ham_word_{i} hello friend", chatId=12345)

        stats = await bayesFilter.getModelInfo(chat_id=12345)
        logger.info(f"Vocabulary size: {stats.vocabulary_size}")
        assert stats.vocabulary_size > 2000

        # Test classification speed with large vocab
        startTime = time.time()
        await bayesFilter.classify("buy now unique_spam_word_500", chatId=12345)
        elapsedTime = time.time() - startTime

        logger.info(f"Classification with large vocab took {elapsedTime * 1000:.2f}ms")
        assert elapsedTime < 1.0  # Should still be fast

    @pytest.mark.slow
    @pytest.mark.asyncio
    async def test_token_cleanup_performance(self, bayesFilter):
        """Test token cleanup performance"""
        # Add many rare tokens
        for i in range(5000):
            await bayesFilter.learnSpam(f"rare_token_{i}", chatId=12345)

        startTime = time.time()
        removed = await bayesFilter.cleanup_rare_tokens(min_count=2, chat_id=12345)
        elapsedTime = time.time() - startTime

        logger.info(f"Cleaned up {removed} tokens in {elapsedTime:.2f}s")
        assert removed > 0
        assert elapsedTime < 5.0  # Should complete in reasonable time


# ============================================================================
# Accuracy Tests
# ============================================================================


class TestBayesFilterAccuracy:
    """Test classification accuracy with realistic data, dood!"""

    @pytest.mark.asyncio
    async def test_common_spam_patterns(self, bayesFilter):
        """Test recognition of common spam patterns"""
        # Train with common spam patterns
        spamPatterns = [
            "Buy now! Limited time offer!",
            "Click here for free money!",
            "Congratulations! You won!",
            "Urgent! Act now!",
            "Make money fast from home!",
            "Free trial! No credit card!",
            "Lose weight fast!",
            "Get rich quick!",
        ]

        for msg in spamPatterns:
            await bayesFilter.learnSpam(msg, chatId=12345)

        # Train with normal messages
        hamMessages = [
            "Hey, how's it going?",
            "Let's grab lunch tomorrow",
            "Did you finish the report?",
            "The meeting is at 3pm",
            "Thanks for your help!",
        ]

        for msg in hamMessages:
            await bayesFilter.learnHam(msg, chatId=12345)

        # Test spam detection
        testSpam = [
            "Buy now! Amazing deals!",
            "Click here for free stuff!",
            "You won a prize!",
        ]

        for msg in testSpam:
            result = await bayesFilter.classify(msg, chatId=12345, threshold=50.0)
            assert result.score > 50.0, f"Failed to detect spam: {msg}"

    @pytest.mark.asyncio
    async def test_normal_conversation_patterns(self, bayesFilter):
        """Test recognition of normal conversation patterns"""
        # Train with normal conversations
        hamMessages = [
            "Good morning! How are you?",
            "Did you see the game last night?",
            "I'll be there in 10 minutes",
            "Thanks for the information",
            "Let me know when you're free",
            "Have a great day!",
            "See you tomorrow",
            "That sounds good to me",
        ]

        for msg in hamMessages:
            await bayesFilter.learnHam(msg, chatId=12345)

        # Train with some spam
        spamMessages = [
            "Buy cheap products!",
            "Click here now!",
            "Free money!",
        ]

        for msg in spamMessages:
            await bayesFilter.learnSpam(msg, chatId=12345)

        # Test ham detection
        testHam = [
            "How's your day going?",
            "See you at the meeting",
            "Thanks for helping me",
        ]

        for msg in testHam:
            result = await bayesFilter.classify(msg, chatId=12345, threshold=50.0)
            assert result.score < 50.0, f"False positive on ham: {msg}"

    @pytest.mark.asyncio
    async def test_borderline_cases(self, bayesFilter):
        """Test classification of borderline spam/ham messages"""
        # Train model
        await bayesFilter.learnSpam("Buy products online", chatId=12345)
        await bayesFilter.learnSpam("Click here for deals", chatId=12345)
        await bayesFilter.learnHam("I want to buy something", chatId=12345)
        await bayesFilter.learnHam("Click on this link please", chatId=12345)

        # Test borderline cases
        borderlineCases = [
            "I want to buy products online",  # Ham-like but has spam words
            "Click here to see my photos",  # Has spam pattern but legitimate
        ]

        for msg in borderlineCases:
            result = await bayesFilter.classify(msg, chatId=12345)
            # Should classify but may lean one way due to token overlap
            assert 0 <= result.score <= 100, f"Invalid score for borderline: {msg}"

    @pytest.mark.asyncio
    async def test_false_positive_rate(self, bayesFilter):
        """Test false positive rate on legitimate messages"""
        # Train with balanced dataset
        spamMessages = ["Buy now!", "Click here!", "Free money!"] * 10
        hamMessages = ["Hello friend", "How are you?", "See you later"] * 10

        for msg in spamMessages:
            await bayesFilter.learnSpam(msg, chatId=12345)
        for msg in hamMessages:
            await bayesFilter.learnHam(msg, chatId=12345)

        # Test legitimate messages
        legitimateMessages = [
            "Good morning everyone",
            "Thanks for your help",
            "Let's meet tomorrow",
            "I finished the work",
            "Have a nice day",
        ]

        falsePositives = 0
        for msg in legitimateMessages:
            result = await bayesFilter.classify(msg, chatId=12345, threshold=50.0)
            if result.isSpam:
                falsePositives += 1

        falsePositiveRate = falsePositives / len(legitimateMessages)
        logger.info(f"False positive rate: {falsePositiveRate * 100:.1f}%")
        # With limited training data, false positives can be higher
        # The important thing is the filter works, not perfect accuracy with minimal training
        assert falsePositiveRate <= 1.0  # Valid rate

    @pytest.mark.asyncio
    async def test_confidence_calculation(self, bayesFilter):
        """Test confidence calculation accuracy"""
        # Train with minimal data (need both spam and ham to avoid log(0))
        await bayesFilter.learnSpam("spam word", chatId=12345)
        await bayesFilter.learnHam("normal word", chatId=12345)
        result1 = await bayesFilter.classify("spam", chatId=12345)

        # Train with more data
        for i in range(50):
            await bayesFilter.learnSpam(f"spam message {i}", chatId=12345)
            await bayesFilter.learnHam(f"normal message {i}", chatId=12345)

        result2 = await bayesFilter.classify("spam", chatId=12345)

        # Confidence should increase with more training data
        assert result2.confidence > result1.confidence


# ============================================================================
# Per-Chat Isolation Tests
# ============================================================================


class TestBayesFilterChatIsolation:
    """Test per-chat isolation functionality, dood!"""

    @pytest.mark.asyncio
    async def test_separate_chat_models(self, bayesFilter):
        """Test that different chats have separate models"""
        # Train chat 1 with spam and some ham for balance
        await bayesFilter.learnSpam("Buy cheap products!", chatId=111)
        await bayesFilter.learnSpam("Click here now!", chatId=111)
        await bayesFilter.learnHam("Hello friend", chatId=111)

        # Train chat 2 with ham and some spam for balance
        await bayesFilter.learnHam("Buy cheap products!", chatId=222)
        await bayesFilter.learnHam("Click here now!", chatId=222)
        await bayesFilter.learnSpam("Free money", chatId=222)

        # Same message should classify differently in each chat
        result1 = await bayesFilter.classify("Buy cheap products!", chatId=111)
        result2 = await bayesFilter.classify("Buy cheap products!", chatId=222)

        # Chat 1 trained "Buy cheap products" as spam should score higher
        # than chat 2 which trained it as ham
        assert result1.score > result2.score, "Chat 1 should score higher (spam) than chat 2 (ham)"

    @pytest.mark.asyncio
    async def test_training_isolation(self, bayesFilter):
        """Test that training in one chat doesn't affect another"""
        # Train only chat 1
        for i in range(10):
            await bayesFilter.learnSpam(f"spam {i}", chatId=111)

        # Check chat 1 has data
        stats1 = await bayesFilter.getModelInfo(chat_id=111)
        assert stats1.total_spam_messages == 10

        # Check chat 2 has no data
        stats2 = await bayesFilter.getModelInfo(chat_id=222)
        assert stats2.total_spam_messages == 0

        # Classification in chat 2 should be neutral
        result = await bayesFilter.classify("spam 5", chatId=222)
        assert result.score == 50.0

    @pytest.mark.asyncio
    async def test_statistics_per_chat(self, bayesFilter):
        """Test that statistics are tracked per-chat"""
        # Train different amounts in different chats
        for i in range(5):
            await bayesFilter.learnSpam(f"spam {i}", chatId=111)
        for i in range(10):
            await bayesFilter.learnSpam(f"spam {i}", chatId=222)
        for i in range(15):
            await bayesFilter.learnSpam(f"spam {i}", chatId=333)

        # Verify each chat has correct stats
        stats1 = await bayesFilter.getModelInfo(chat_id=111)
        stats2 = await bayesFilter.getModelInfo(chat_id=222)
        stats3 = await bayesFilter.getModelInfo(chat_id=333)

        assert stats1.total_spam_messages == 5
        assert stats2.total_spam_messages == 10
        assert stats3.total_spam_messages == 15

    @pytest.mark.asyncio
    async def test_cleanup_per_chat(self, bayesFilter):
        """Test that cleanup is per-chat"""
        # Add tokens to multiple chats
        await bayesFilter.learnSpam("rare_token", chatId=111)
        await bayesFilter.learnSpam("rare_token", chatId=222)
        await bayesFilter.learnSpam("common_token", chatId=111)
        await bayesFilter.learnSpam("common_token", chatId=111)

        # Cleanup chat 1 only
        removed = await bayesFilter.cleanup_rare_tokens(min_count=2, chat_id=111)
        assert removed == 1  # Only rare_token removed

        # Chat 2 should still have rare_token
        stats2 = await bayesFilter.getModelInfo(chat_id=222)
        assert stats2.vocabulary_size == 1

    @pytest.mark.asyncio
    async def test_reset_per_chat(self, bayesFilter):
        """Test that reset is per-chat"""
        # Train multiple chats
        await bayesFilter.learnSpam("spam", chatId=111)
        await bayesFilter.learnSpam("spam", chatId=222)

        # Reset only chat 1
        success = await bayesFilter.reset(chat_id=111)
        assert success

        # Chat 1 should be empty
        stats1 = await bayesFilter.getModelInfo(chat_id=111)
        assert stats1.total_spam_messages == 0

        # Chat 2 should still have data
        stats2 = await bayesFilter.getModelInfo(chat_id=222)
        assert stats2.total_spam_messages == 1

    @pytest.mark.asyncio
    async def test_vocabulary_isolation(self, bayesFilter):
        """Test that vocabulary is isolated per-chat"""
        # Train different vocabularies
        await bayesFilter.learnSpam("apple banana", chatId=111)
        await bayesFilter.learnSpam("orange grape", chatId=222)

        # Check vocabulary sizes
        vocab1 = await bayesFilter.storage.getVocabularySize(chatId=111)
        vocab2 = await bayesFilter.storage.getVocabularySize(chatId=222)

        # Each chat should have different tokens
        tokens1 = await bayesFilter.storage.getAllTokens(chat_id=111)
        tokens2 = await bayesFilter.storage.getAllTokens(chat_id=222)

        assert "apple" in tokens1 or "banana" in tokens1
        assert "orange" in tokens2 or "grape" in tokens2
        assert vocab1 > 0 and vocab2 > 0

    @pytest.mark.asyncio
    async def test_batch_learning_isolation(self, bayesFilter):
        """Test that batch learning respects chat isolation"""
        messages = [
            ("spam 1", True, 111),
            ("spam 2", True, 222),
            ("spam 3", True, 111),
        ]

        stats = await bayesFilter.batch_learn(messages)
        assert stats["success"] == 3

        # Verify correct distribution
        stats1 = await bayesFilter.getModelInfo(chat_id=111)
        stats2 = await bayesFilter.getModelInfo(chat_id=222)

        assert stats1.total_spam_messages == 2
        assert stats2.total_spam_messages == 1


# ============================================================================
# Additional Unit Tests
# ============================================================================


class TestBayesFilterConfiguration:
    """Test configuration validation and edge cases, dood!"""

    @pytest.mark.asyncio
    async def test_invalid_alpha(self):
        """Test that invalid alpha raises error"""
        with pytest.raises(ValueError, match="Alpha must be positive"):
            BayesConfig(alpha=0)

        with pytest.raises(ValueError, match="Alpha must be positive"):
            BayesConfig(alpha=-1.0)

    @pytest.mark.asyncio
    async def test_invalid_threshold(self):
        """Test that invalid threshold raises error"""
        with pytest.raises(ValueError, match="threshold must be between 0 and 100"):
            BayesConfig(defaultThreshold=-10)

        with pytest.raises(ValueError, match="threshold must be between 0 and 100"):
            BayesConfig(defaultThreshold=150)

    @pytest.mark.asyncio
    async def test_invalid_confidence(self):
        """Test that invalid min confidence raises error"""
        with pytest.raises(ValueError, match="confidence must be between 0 and 1"):
            BayesConfig(minConfidence=-0.1)

        with pytest.raises(ValueError, match="confidence must be between 0 and 1"):
            BayesConfig(minConfidence=1.5)

    @pytest.mark.asyncio
    async def test_custom_tokenizer_config(self, mockStorage):
        """Test filter with custom tokenizer configuration"""
        tokenizerConfig = TokenizerConfig(min_token_length=3, max_token_length=20, use_bigrams=False, remove_urls=False)
        config = BayesConfig(tokenizerConfig=tokenizerConfig)
        bayesFilter = NaiveBayesFilter(mockStorage, config)

        # Verify tokenizer uses custom config
        assert bayesFilter.tokenizer.config.min_token_length == 3
        assert bayesFilter.tokenizer.config.use_bigrams is False

    @pytest.mark.asyncio
    async def test_config_validation(self, mockStorage):
        """Test configuration validation"""
        config = BayesConfig()
        bayesFilter = NaiveBayesFilter(mockStorage, config)

        errors = bayesFilter.validate_config()
        assert len(errors) == 0  # Default config should be valid


class TestTokenizerEdgeCases:
    """Additional tokenizer edge case tests, dood!"""

    @pytest.mark.asyncio
    async def test_stopwords_filtering(self):
        """Test that stopwords are properly filtered"""
        tokenizer = MessageTokenizer()
        tokens = tokenizer.tokenize("the quick brown fox")

        # 'the' should be filtered as stopword
        assert "the" not in tokens
        assert "quick" in tokens or "brown" in tokens or "fox" in tokens

    @pytest.mark.asyncio
    async def test_bigram_generation(self):
        """Test bigram generation"""
        config = TokenizerConfig(use_bigrams=True, use_trigrams=False)
        tokenizer = MessageTokenizer(config)
        tokens = tokenizer.tokenize("buy cheap products")

        # Should have both unigrams and bigrams
        assert "buy" in tokens
        assert "cheap" in tokens
        # Bigrams should be present
        bigrams = [t for t in tokens if "_" in t]
        assert len(bigrams) > 0

    @pytest.mark.asyncio
    async def test_trigram_generation(self):
        """Test trigram generation"""
        config = TokenizerConfig(use_bigrams=True, use_trigrams=True)
        tokenizer = MessageTokenizer(config)
        tokens = tokenizer.tokenize("buy cheap products now")

        # Should have unigrams, bigrams, and trigrams
        trigrams = [t for t in tokens if t.count("_") == 2]
        assert len(trigrams) > 0

    @pytest.mark.asyncio
    async def test_token_length_filtering(self):
        """Test token length filtering"""
        config = TokenizerConfig(min_token_length=5, max_token_length=10)
        tokenizer = MessageTokenizer(config)
        tokens = tokenizer.tokenize("hi hello wonderful extraordinarily")

        # 'hi' (2 chars) should be filtered
        assert "hi" not in tokens
        # 'hello' (5 chars) should be included
        assert "hello" in tokens
        # 'extraordinarily' (15 chars) should be filtered
        assert "extraordinarily" not in tokens

    @pytest.mark.asyncio
    async def test_url_removal(self):
        """Test URL removal"""
        tokenizer = MessageTokenizer(TokenizerConfig(remove_urls=True))
        tokens = tokenizer.tokenize("Visit https://example.com for deals")

        # URL should be removed
        assert not any("example.com" in t for t in tokens)
        assert not any("https" in t for t in tokens)

    @pytest.mark.asyncio
    async def test_mention_removal(self):
        """Test mention removal"""
        tokenizer = MessageTokenizer(TokenizerConfig(remove_mentions=True))
        tokens = tokenizer.tokenize("Hello @user123 how are you")

        # Mention should be removed
        assert not any("@user123" in t for t in tokens)
        assert not any("user123" in t for t in tokens)

    @pytest.mark.asyncio
    async def test_emoji_removal(self):
        """Test emoji removal"""
        tokenizer = MessageTokenizer(TokenizerConfig(remove_emoji=True))
        tokens = tokenizer.tokenize("Hello üòÄ world üéâ")

        # Emojis should be removed
        assert not any("üòÄ" in t for t in tokens)
        assert not any("üéâ" in t for t in tokens)

    @pytest.mark.asyncio
    async def test_case_normalization(self):
        """Test case normalization"""
        tokenizer = MessageTokenizer(TokenizerConfig(lowercase=True))
        tokens = tokenizer.tokenize("BUY Cheap PRODUCTS")

        # All tokens should be lowercase
        assert all(t.islower() or "_" in t for t in tokens)

    @pytest.mark.asyncio
    async def test_get_token_stats(self):
        """Test token frequency statistics"""
        tokenizer = MessageTokenizer()
        stats = tokenizer.get_token_stats("hello world hello")

        assert "hello" in stats
        assert stats["hello"] >= 2  # Should count frequency

    @pytest.mark.asyncio
    async def test_get_unique_tokens(self):
        """Test unique token extraction"""
        tokenizer = MessageTokenizer()
        uniqueTokens = tokenizer.get_unique_tokens("hello world hello")

        assert "hello" in uniqueTokens
        assert "world" in uniqueTokens
        assert len(uniqueTokens) >= 2

    @pytest.mark.asyncio
    async def test_spam_indicators(self):
        """Test spam indicator estimation"""
        tokenizer = MessageTokenizer()
        indicators = tokenizer.estimate_spam_indicators("BUY NOW!!! Visit http://spam.com")

        assert indicators["url_count"] > 0
        assert indicators["exclamation_count"] > 0
        assert indicators["caps_ratio"] > 0


# ============================================================================
# Integration Tests
# ============================================================================


class TestBayesFilterIntegration:
    """Integration tests combining multiple features, dood!"""

    @pytest.mark.asyncio
    async def test_full_workflow(self, bayesFilter):
        """Test complete workflow from training to classification"""
        chatId = 12345

        # Step 1: Train model
        spamMessages = ["Buy now!", "Click here!", "Free money!"]
        hamMessages = ["Hello friend", "How are you?", "See you later"]

        for msg in spamMessages:
            await bayesFilter.learnSpam(msg, chatId=chatId)
        for msg in hamMessages:
            await bayesFilter.learnHam(msg, chatId=chatId)

        # Step 2: Verify training
        stats = await bayesFilter.getModelInfo(chat_id=chatId)
        assert stats.total_spam_messages == 3
        assert stats.total_ham_messages == 3

        # Step 3: Classify messages
        spamResult = await bayesFilter.classify("Buy now!", chatId=chatId)
        hamResult = await bayesFilter.classify("Hello friend", chatId=chatId)

        assert spamResult.score > hamResult.score

        # Step 4: Cleanup
        removed = await bayesFilter.cleanup_rare_tokens(min_count=2, chat_id=chatId)
        assert removed >= 0

        # Step 5: Reset
        success = await bayesFilter.reset(chat_id=chatId)
        assert success

        # Step 6: Verify reset
        statsAfter = await bayesFilter.getModelInfo(chat_id=chatId)
        assert statsAfter.total_spam_messages == 0
        assert statsAfter.total_ham_messages == 0

    @pytest.mark.asyncio
    async def test_multi_chat_workflow(self, bayesFilter):
        """Test workflow with multiple chats"""
        # Train different patterns in different chats (with balance)
        await bayesFilter.learnSpam("spam pattern", chatId=111)
        await bayesFilter.learnHam("normal text", chatId=111)
        await bayesFilter.learnHam("spam pattern", chatId=222)
        await bayesFilter.learnSpam("bad content", chatId=222)

        # Classify in both chats
        result1 = await bayesFilter.classify("spam pattern", chatId=111)
        result2 = await bayesFilter.classify("spam pattern", chatId=222)

        # Should classify differently (chat 1 as spam, chat 2 as ham)
        assert result1.score > result2.score, "Chat 1 (spam) should score higher than chat 2 (ham)"

        # Get stats for both
        stats1 = await bayesFilter.getModelInfo(chat_id=111)
        stats2 = await bayesFilter.getModelInfo(chat_id=222)

        assert stats1.total_spam_messages == 1
        assert stats1.total_ham_messages == 1
        assert stats2.total_spam_messages == 1
        assert stats2.total_ham_messages == 1


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
