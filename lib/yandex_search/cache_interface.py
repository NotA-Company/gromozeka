"""
Abstract cache interface for Yandex Search data caching

This module defines the abstract interface that all search cache implementations
must follow. The interface provides a contract for caching search results,
enabling different storage backends (in-memory, database, Redis, etc.) to be
used interchangeably.

The caching strategy is designed to:
- Reduce API calls by storing frequently accessed results
- Improve response times for repeated queries
- Provide configurable TTL (Time To Live) for cached entries
- Support cache bypassing when fresh results are needed

This interface follows the same pattern used in lib/openweathermap/cache_interface.py
to maintain consistency across the project's caching implementations.

Example:
    ```python
    class MyCustomCache(SearchCacheInterface):
        async def getSearch(self, key: str, ttl: Optional[int] = None) -> Optional[SearchResponse]:
            # Implementation for retrieving cached search results
            pass

        async def setSearch(self, key: str, data: SearchResponse) -> bool:
            # Implementation for storing search results
            pass

    # Use with the client
    cache = MyCustomCache()
    client = YandexSearchClient(
        iam_token="your_token",
        folder_id="your_folder",
        cache=cache
    )
    ```
"""

from abc import ABC, abstractmethod
from typing import Optional

from .models import SearchResponse


class SearchCacheInterface(ABC):
    """
    Abstract interface for search data caching.

    This interface defines the contract that all search cache implementations
    must follow. It provides methods for storing and retrieving SearchResponse
    objects with support for TTL (Time To Live) expiration.

    Implementations can use various storage backends:
    - In-memory dictionaries (DictSearchCache)
    - Database tables (DatabaseSearchCache)
    - Redis or other key-value stores
    - File-based storage

    The interface is designed to be async-compatible to work with the
    async YandexSearchClient without blocking operations.

    Cache Key Generation:
    Cache keys are typically generated by the client using a hash of the
    search parameters. The same query should always generate the same key
    to ensure cache hits.

    Thread Safety:
    Implementations should be thread-safe if they might be used in
    concurrent environments. Use appropriate locking mechanisms.

    Example Implementation:
        ```python
        class RedisSearchCache(SearchCacheInterface):
            def __init__(self, redis_client):
                self.redis = redis_client

            async def getSearch(self, key: str, ttl: Optional[int] = None) -> Optional[SearchResponse]:
                data = await self.redis.get(key)
                if data:
                    # Check if expired based on stored timestamp
                    return json.loads(data)
                return None

            async def setSearch(self, key: str, data: SearchResponse) -> bool:
                await self.redis.setex(key, 3600, json.dumps(data))
                return True
        ```
    """

    @abstractmethod
    async def getSearch(self, key: str, ttl: Optional[int] = None) -> Optional[SearchResponse]:
        """
        Retrieve cached search results by key.

        This method should return the cached SearchResponse if it exists
        and hasn't expired. The TTL parameter allows for flexible expiration
        checking - if provided, it should override any default TTL.

        Args:
            key (str): Cache key based on query parameters.
                      Typically an MD5 hash generated by the client.
            ttl (Optional[int]): TTL in seconds for expiration checking.
                               If None, use the cache's default TTL.
                               If 0, treat as always expired.
                               If negative, treat as never expired.

        Returns:
            Optional[SearchResponse]: The cached SearchResponse if found and
                                    not expired, None otherwise.

        Note:
            - Implementations should handle cache misses gracefully
            - Expired entries should be removed if possible
            - Return None for any errors (don't raise exceptions)
            - The method should be async-compatible

        Example:
            ```python
            # Get with default TTL
            result = await cache.getSearch("abc123")

            # Get with custom TTL check
            result = await cache.getSearch("abc123", ttl=1800)  # 30 minutes
            ```
        """
        pass

    @abstractmethod
    async def setSearch(self, key: str, data: SearchResponse) -> bool:
        """
        Store search results in cache.

        This method should store the SearchResponse with the provided key.
        The implementation should handle the storage timestamp for TTL
        calculations and manage cache size if necessary.

        Args:
            key (str): Cache key for storing the data.
                      Should match the key used for retrieval.
            data (SearchResponse): The search response data to cache.
                                 Contains search results, metadata, and error info.

        Returns:
            bool: True if the data was successfully stored, False otherwise.

        Note:
            - Implementations should handle storage errors gracefully
            - Consider cache size limits and eviction policies
            - Store timestamps for TTL calculations
            - The method should be async-compatible
            - Don't raise exceptions for expected failures

        Example:
            ```python
            success = await cache.setSearch("abc123", search_response)
            if not success:
                logger.warning("Failed to cache search result")
            ```
        """
        pass
